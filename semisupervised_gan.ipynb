{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVHN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SvhnDataset(Dataset):\n",
    "    def __init__(self, image_size, split):\n",
    "        self.split = split\n",
    "        self.use_gpu = True if torch.cuda.is_available() else False\n",
    "\n",
    "        self.svhn_dataset = self._create_dataset(image_size, split)\n",
    "        self.label_mask = self._create_label_mask()\n",
    "\n",
    "    def _create_dataset(self, image_size, split):\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],\n",
    "            std=[0.5, 0.5, 0.5])\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "        return datasets.SVHN(root='./svhn', download=True, transform=transform, split=split)\n",
    "\n",
    "    def _is_train_dataset(self):\n",
    "        return True if self.split == 'train' else False\n",
    "\n",
    "    def _create_label_mask(self):\n",
    "        if self._is_train_dataset():\n",
    "            label_mask = torch.zeros(len(self.svhn_dataset)).float()\n",
    "            label_mask[0:1000] = 1\n",
    "            return label_mask\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.svhn_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.svhn_dataset.__getitem__(idx)\n",
    "        if self._is_train_dataset():\n",
    "            return data, label, self.label_mask[idx]\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(image_size, batch_size):\n",
    "    num_workers = 1\n",
    "\n",
    "    svhn_train = SvhnDataset(image_size=image_size, split='train')\n",
    "    svhn_test = SvhnDataset(image_size=image_size, split='test')\n",
    "\n",
    "    svhn_loader_train = DataLoader(\n",
    "        dataset=svhn_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    svhn_loader_test = DataLoader(\n",
    "        dataset=svhn_test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return svhn_loader_train, svhn_loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_loader_train, _ = get_loader(image_size=32, batch_size=36)\n",
    "image_iter = iter(svhn_loader_train)\n",
    "images, _, _ = image_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_images(images):\n",
    "    assert(len(images) >= 36)\n",
    "    fig, axes = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(5,5))\n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        img = images[idx].numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        img = ((img - img.min())*255 / (img.max() - img.min())).astype(np.uint8)\n",
    "        ax.imshow(img, aspect='equal')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv, deconv helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    '''\n",
    "    GAN generator\n",
    "    '''\n",
    "    def __init__(self, num_noise_channels, size_mult, lrelu_alpha, num_output_channels):\n",
    "        super(_netG, self).__init__()\n",
    "        self.lrelu_alpha = lrelu_alpha\n",
    "\n",
    "        # noise is going into a convolution\n",
    "        self.deconv1 = deconv(\n",
    "            c_in=num_noise_channels,\n",
    "            c_out=size_mult * 4,\n",
    "            k_size=4,\n",
    "            stride=1,\n",
    "            pad=0)\n",
    "        # (size_mult * 4) x 4 x 4\n",
    "\n",
    "        self.deconv2 = deconv(\n",
    "            c_in=size_mult * 4,\n",
    "            c_out=size_mult * 2,\n",
    "            k_size=4)\n",
    "        # (size_mult * 2) x 8 x 8\n",
    "\n",
    "        self.deconv3 = deconv(\n",
    "            c_in=size_mult * 2,\n",
    "            c_out=size_mult * 1,\n",
    "            k_size=4)\n",
    "        # (size_mult) x 16 x 16\n",
    "\n",
    "        self.deconv4 = deconv(\n",
    "            c_in=size_mult,\n",
    "            c_out=num_output_channels,\n",
    "            k_size=4,\n",
    "            bn=False)\n",
    "        # (num_output_channels) x 16 x 16\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = F.leaky_relu(self.deconv1(inputs), self.lrelu_alpha)\n",
    "        out = F.leaky_relu(self.deconv2(out), self.lrelu_alpha)\n",
    "        out = F.leaky_relu(self.deconv3(out), self.lrelu_alpha)\n",
    "        out = F.tanh(self.deconv4(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    '''\n",
    "    GAN discruminator\n",
    "    '''\n",
    "    def __init__(self, size_mult, lrelu_alpha, number_channels, drop_rate, num_classes):\n",
    "        super(_netD, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lrelu_alpha = lrelu_alpha\n",
    "        self.size_mult = size_mult\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # input is (number_channels) x 32 x 32\n",
    "        self.conv1 = conv(\n",
    "            c_in=number_channels,\n",
    "            c_out=size_mult,\n",
    "            k_size=3,\n",
    "            bn=False\n",
    "        )\n",
    "        # (size_mult) x 16 x 16\n",
    "\n",
    "        self.conv2 = conv(\n",
    "            c_in=size_mult,\n",
    "            c_out=size_mult,\n",
    "            k_size=3,\n",
    "        )\n",
    "        # (size_mult) x 8 x 8\n",
    "\n",
    "        self.conv3 = conv(\n",
    "            c_in=size_mult,\n",
    "            c_out=size_mult,\n",
    "            k_size=3,\n",
    "        )\n",
    "        # (size_mult) x 4 x 4\n",
    "\n",
    "        self.conv4 = conv(\n",
    "            c_in=size_mult,\n",
    "            c_out=size_mult * 2,\n",
    "            k_size=3,\n",
    "            stride=1\n",
    "        )\n",
    "        # (size_mult * 2) x 4 x 4\n",
    "\n",
    "        self.conv5 = conv(\n",
    "            c_in=size_mult * 2,\n",
    "            c_out=size_mult * 2,\n",
    "            k_size=3,\n",
    "            stride=1\n",
    "        )\n",
    "        # (size_mult * 2) x 4 x 4\n",
    "\n",
    "        self.conv6 = conv(\n",
    "            c_in=size_mult * 2,\n",
    "            c_out=size_mult * 2,\n",
    "            k_size=3,\n",
    "            stride=1,\n",
    "            pad=0,\n",
    "            bn=False\n",
    "        )\n",
    "        # (size_mult * 2) x 2 x 2\n",
    "\n",
    "        self.features = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.class_logits = nn.Linear(\n",
    "            in_features=(size_mult * 2) * 1 * 1,\n",
    "            out_features=num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = F.dropout2d(inputs, p=self.drop_rate/2.5)\n",
    "\n",
    "        out = F.leaky_relu(self.conv1(out), self.lrelu_alpha)\n",
    "        out = F.dropout2d(out, p=self.drop_rate)\n",
    "\n",
    "        out = F.leaky_relu(self.conv2(out), self.lrelu_alpha)\n",
    "\n",
    "        out = F.leaky_relu(self.conv3(out), self.lrelu_alpha)\n",
    "        out = F.dropout2d(out, p=self.drop_rate)\n",
    "\n",
    "        out = F.leaky_relu(self.conv4(out), self.lrelu_alpha)\n",
    "\n",
    "        out = F.leaky_relu(self.conv5(out), self.lrelu_alpha)\n",
    "\n",
    "        out = F.leaky_relu(self.conv6(out), self.lrelu_alpha)\n",
    "\n",
    "        features = self.features(out)\n",
    "        features = features.squeeze()\n",
    "\n",
    "        class_logits = self.class_logits(features)\n",
    "\n",
    "        # calculate gan logits\n",
    "        max_val, _ = torch.max(class_logits, 1, keepdim=True)\n",
    "        stable_class_logits = class_logits - max_val\n",
    "        max_val = torch.squeeze(max_val)\n",
    "        gan_logits = torch.log(torch.sum(torch.exp(stable_class_logits), 1)) + max_val\n",
    "\n",
    "        out = F.softmax(class_logits, dim=0)\n",
    "\n",
    "        return out, class_logits, gan_logits, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import _netG, _netD\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, svhn_loader_train, svhn_loader_test, batch_size):\n",
    "        self.nz = 100\n",
    "        self.real_image_size = (3, 32, 32)\n",
    "        self.lrelu_alpha = 1e-2\n",
    "        self.drop_rate = .5\n",
    "        self.g_size_mult = 32\n",
    "        self.d_size_mult = 64\n",
    "        self.num_classes = 10\n",
    "        self.use_gpu = True if torch.cuda.is_available() else False\n",
    "        self.learning_rate = 3e-3\n",
    "        self.beta1 = .5\n",
    "        self.svhn_loader_train = svhn_loader_train\n",
    "        self.svhn_loader_test = svhn_loader_test\n",
    "        self.epochs = 25\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.generator, self.discriminator = self._build_model()\n",
    "        self.g_optimizer, self.d_optimizer = self._create_optimizers()\n",
    "\n",
    "    def _build_model(self):\n",
    "        generator = _netG(\n",
    "            self.nz, self.g_size_mult, self.lrelu_alpha,\n",
    "            self.real_image_size[0])\n",
    "        generator.apply(self._weights_init)\n",
    "        # TODO: load weights from file if it exists\n",
    "\n",
    "        discriminator = _netD(\n",
    "            self.d_size_mult, self.lrelu_alpha, self.real_image_size[0],\n",
    "            self.drop_rate, self.num_classes)\n",
    "        discriminator.apply(self._weights_init)\n",
    "        # TODO: load weights from file if it exists\n",
    "\n",
    "        if self.use_gpu:\n",
    "            generator = generator.cuda()\n",
    "            discriminator = discriminator.cuda()\n",
    "\n",
    "        return generator, discriminator\n",
    "\n",
    "    def _weights_init(self, module):\n",
    "        '''\n",
    "        Custom weights initialization called on generator and discriminator\n",
    "        '''\n",
    "        classname = module.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            module.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            module.weight.data.normal_(1.0, 0.02)\n",
    "            module.bias.data.fill_(0)\n",
    "\n",
    "    def _create_optimizers(self):\n",
    "        g_params = list(self.generator.parameters())\n",
    "        d_params = list(self.discriminator.parameters())\n",
    "\n",
    "        g_optimizer = optim.Adam(g_params, self.learning_rate)\n",
    "        d_optimizer = optim.Adam(d_params, self.learning_rate)\n",
    "\n",
    "        return g_optimizer, d_optimizer\n",
    "\n",
    "    def _to_var(self, x):\n",
    "        if self.use_gpu:\n",
    "            x = x.cuda()\n",
    "        return Variable(x)\n",
    "\n",
    "    def _one_hot(self, x):\n",
    "        ones = torch.sparse.torch.eye(self.num_classes)\n",
    "        one_hot = ones.index_select(0, x.data.cpu())\n",
    "        if self.use_gpu:\n",
    "            one_hot = one_hot.cuda()\n",
    "        return Variable(one_hot)\n",
    "\n",
    "    def train(self):\n",
    "        svhn_iter = iter(self.svhn_loader_train)\n",
    "        iter_per_epoch = len(svhn_iter)\n",
    "        print(iter_per_epoch)\n",
    "\n",
    "        d_gan_criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        noise = torch.FloatTensor(self.batch_size, self.nz, 1, 1)\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            masked_correct = 0\n",
    "            num_samples = 0\n",
    "            total_count_samples = 0\n",
    "            loop_count = 0\n",
    "\n",
    "            for _, data in enumerate(self.svhn_loader_train):\n",
    "                # load svhn dataset\n",
    "                svhn_data, svhn_labels, label_mask = data\n",
    "                svhn_data = self._to_var(svhn_data)\n",
    "                svhn_labels = self._to_var(svhn_labels).long().squeeze()\n",
    "                label_mask = self._to_var(label_mask).float().squeeze()\n",
    "\n",
    "                # -------------- train discriminator --------------\n",
    "\n",
    "                # train with real images\n",
    "                self.d_optimizer.zero_grad()\n",
    "\n",
    "                # d_out == softmax(d_class_logits)\n",
    "                d_out, d_class_logits_on_data, d_gan_logits_real, d_sample_features = self.discriminator(svhn_data)\n",
    "                d_gan_labels_real = self._to_var(torch.ones_like(d_gan_logits_real.data))\n",
    "                d_gan_loss_real = d_gan_criterion(\n",
    "                    d_gan_logits_real,\n",
    "                    d_gan_labels_real)\n",
    "\n",
    "                # train with fake images\n",
    "                noise.resize_(self.batch_size, self.nz, 1, 1).normal_(0, 1)\n",
    "                noise_var = self._to_var(noise)\n",
    "                fake = self.generator(noise_var)\n",
    "\n",
    "                # call detach() to avoid backprop for generator here\n",
    "                _, _, d_gan_logits_fake, _ = self.discriminator(fake.detach())\n",
    "\n",
    "                d_gan_labels_fake = self._to_var(torch.zeros_like(d_gan_logits_fake.data))\n",
    "                d_gan_loss_fake = d_gan_criterion(\n",
    "                    d_gan_logits_fake,\n",
    "                    d_gan_labels_fake)\n",
    "\n",
    "                d_gan_loss = d_gan_loss_real + d_gan_loss_fake\n",
    "\n",
    "                # d_out == softmax(d_class_logits)\n",
    "                # see https://stackoverflow.com/questions/34240703/whats-the-difference-between-softmax-and-softmax-cross-entropy-with-logits/39499486#39499486\n",
    "                svhn_labels_one_hot = self._one_hot(svhn_labels)\n",
    "                d_class_loss_entropy = -torch.sum(svhn_labels_one_hot * torch.log(d_out), dim=1)\n",
    "                \n",
    "                # d_class_loss_entropy = d_class_criterion(\n",
    "                #     d_class_logits_on_data,\n",
    "                #     self._one_hot(svhn_labels)\n",
    "                # )\n",
    "\n",
    "                d_class_loss_entropy = d_class_loss_entropy.squeeze()\n",
    "                delim = torch.max(torch.Tensor([1.0, torch.sum(label_mask.data)]))\n",
    "                d_class_loss = torch.sum(label_mask * d_class_loss_entropy) / delim\n",
    "                \n",
    "                d_loss = d_gan_loss + d_class_loss\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # -------------- update generator --------------\n",
    "                \n",
    "                self.g_optimizer.zero_grad()\n",
    "\n",
    "                # call discriminator again to do backprop for generator here\n",
    "                _, _, _, d_data_features = self.discriminator(fake)\n",
    "                \n",
    "                # Here we set `g_loss` to the \"feature matching\" loss invented by Tim Salimans at OpenAI.\n",
    "                # This loss consists of minimizing the absolute difference between the expected features\n",
    "                # on the data and the expected features on the generated samples.\n",
    "                # This loss works better for semi-supervised learning than the tradition GAN losses.\n",
    "                data_features_mean = torch.mean(d_data_features, dim=0)\n",
    "                sample_features_mean = torch.mean(d_sample_features.detach(), dim=0)\n",
    "                \n",
    "                g_loss = torch.mean(torch.abs(data_features_mean - sample_features_mean))\n",
    "\n",
    "                _, pred_class = torch.max(d_class_logits_on_data, 1)\n",
    "                eq = torch.eq(svhn_labels, pred_class)\n",
    "                correct = torch.sum(eq.float())\n",
    "                masked_correct += torch.sum(label_mask * eq.float())\n",
    "                num_samples += torch.sum(label_mask)\n",
    "\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                total_count_samples += len(svhn_labels)\n",
    "                loop_count += 1\n",
    "                # if loop_count%10 == 0:\n",
    "                #    print('Training:\\tepoch {}/{}\\tdiscr. gan loss {}\\tdiscr. class loss {}\\tgen loss {}\\tsamples {}/{}'.\n",
    "                #            format(epoch, self.epochs, d_gan_loss.data[0], d_class_loss.data[0], g_loss.data[0], \n",
    "                #                total_count_samples, len(self.svhn_loader_train)))\n",
    "                    \n",
    "            accuracy = masked_correct.data[0]/max(1.0, num_samples.data[0])\n",
    "            print('Training:\\tepoch {}/{}\\taccuracy {}'.format(epoch, self.epochs, accuracy))\n",
    "\n",
    "            total_count_samples = 0\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "            loop_count = 0\n",
    "            for _, data in enumerate(self.svhn_loader_test):\n",
    "                # load svhn dataset\n",
    "                svhn_data, svhn_labels = data\n",
    "                svhn_data = self._to_var(svhn_data)\n",
    "                svhn_labels = self._to_var(svhn_labels).long().squeeze()\n",
    "\n",
    "                # -------------- train discriminator --------------\n",
    "\n",
    "                # train with real images\n",
    "                d_out, _, _, _ = self.discriminator(svhn_data)\n",
    "                _, pred_idx = torch.max(d_out.data, 1)\n",
    "                eq = torch.eq(svhn_labels.data, pred_idx)\n",
    "                correct += torch.sum(eq.float())\n",
    "                num_samples += len(svhn_labels)\n",
    "                \n",
    "                total_count_samples += len(svhn_labels)\n",
    "                loop_count += 1\n",
    "                # if loop_count%10 == 0:\n",
    "                #    print('Test:\\tepoch {}/{}\\tsamples {}/{}'.format(\n",
    "                #        epoch, self.epochs, total_count_samples, len(self.svhn_loader_test)))\n",
    "                \n",
    "            accuracy = correct/max(1.0, 1.0 * num_samples)\n",
    "            print('Test:\\tepoch {}/{}\\taccuracy {}'.format(epoch, self.epochs, accuracy))\n",
    "\n",
    "            # TODO: save checkpoints and the best model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./svhn/train_32x32.mat\n",
      "Using downloaded and verified file: ./svhn/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_loader_train, svhn_loader_test = get_loader(image_size, batch_size)\n",
    "solver = Solver(svhn_loader_train, svhn_loader_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n",
      "Training:\tepoch 1/25\taccuracy 0.096\n",
      "Test:\tepoch 1/25\taccuracy 0.08428088506453596\n",
      "Training:\tepoch 2/25\taccuracy 0.064\n",
      "Test:\tepoch 2/25\taccuracy 0.10517824216349109\n",
      "Training:\tepoch 3/25\taccuracy 0.066\n",
      "Test:\tepoch 3/25\taccuracy 0.10003073140749846\n",
      "Training:\tepoch 4/25\taccuracy 0.064\n",
      "Test:\tepoch 4/25\taccuracy 0.0806699446834665\n",
      "Training:\tepoch 5/25\taccuracy 0.063\n",
      "Test:\tepoch 5/25\taccuracy 0.11086355255070682\n",
      "Training:\tepoch 6/25\taccuracy 0.064\n",
      "Test:\tepoch 6/25\taccuracy 0.11140135218192994\n",
      "Training:\tepoch 7/25\taccuracy 0.062\n",
      "Test:\tepoch 7/25\taccuracy 0.10337277197295636\n",
      "Training:\tepoch 8/25\taccuracy 0.065\n",
      "Test:\tepoch 8/25\taccuracy 0.107559926244622\n",
      "Training:\tepoch 9/25\taccuracy 0.066\n",
      "Test:\tepoch 9/25\taccuracy 0.11328365089121081\n",
      "Training:\tepoch 10/25\taccuracy 0.062\n",
      "Test:\tepoch 10/25\taccuracy 0.14393822987092808\n",
      "Training:\tepoch 11/25\taccuracy 0.066\n",
      "Test:\tepoch 11/25\taccuracy 0.1840043023970498\n",
      "Training:\tepoch 12/25\taccuracy 0.065\n",
      "Test:\tepoch 12/25\taccuracy 0.18984326982175784\n",
      "Training:\tepoch 13/25\taccuracy 0.062\n",
      "Test:\tepoch 13/25\taccuracy 0.21354486785494775\n",
      "Training:\tepoch 14/25\taccuracy 0.064\n",
      "Test:\tepoch 14/25\taccuracy 0.27604486785494775\n",
      "Training:\tepoch 15/25\taccuracy 0.067\n",
      "Test:\tepoch 15/25\taccuracy 0.2889136447449293\n",
      "Training:\tepoch 16/25\taccuracy 0.072\n",
      "Test:\tepoch 16/25\taccuracy 0.3519898586355255\n",
      "Training:\tepoch 17/25\taccuracy 0.069\n",
      "Test:\tepoch 17/25\taccuracy 0.3711585740626921\n",
      "Training:\tepoch 18/25\taccuracy 0.074\n",
      "Test:\tepoch 18/25\taccuracy 0.3806084818684696\n",
      "Training:\tepoch 19/25\taccuracy 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-2-ec16e050f298>\", line 33, in __getitem__\n",
      "    data, label = self.svhn_dataset.__getitem__(idx)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/svhn.py\", line 99, in __getitem__\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/functional.py\", line 74, in to_tensor\n",
      "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ad90b845b08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ea01c0d90046>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mloop_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvhn_loader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;31m# load svhn dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0msvhn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
